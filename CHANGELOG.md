# 智简笔记本 (WitNote) - 开发进度报告

> 大智若简，落笔生花 | 本地优先的 AI 写作伴侣

---

## 📌 当前版本: v1.2.0

**最后更新**: 2025-12-19

---

## 🚀 v1.2.0 发布亮点

- 🔧 **内置 AI 模型**: 应用包含 `qwen2.5:0.5b` 模型，开箱即用，无需额外下载
- ✅ **下载验证机制**: 模型下载后自动验证文件完整性，确保模型可用
- 🍎 **Apple 公证**: Mac 版本已通过 Apple 官方公证，无需手动信任开发者
- 🪟 **Windows 标题栏优化**: 使用原生系统标题栏，更好的 Windows 体验
- 🐛 **修复多语言翻译**: 完善 Chat 区域的中英文翻译

---

## ✅ Phase 3: 交互体验升级 (已完成)

### A. 沉浸式文件管理
- [x] **卡片网格视图**
  - iOS 风格文件卡片设计
  - 智能网格布局 (`display: grid`)
  - 卡片悬停/选中状态微交互
  - 未染色卡片的新视觉风格（白色背景 + 灰色阴影）

- [x] **智能拖拽排序系统**
  - **拖拽体验重构**: 
    - 拖拽时卡片半透明悬浮跟随
    - 原位置完全隐藏，实现真实移动感
    - 实时计算插入位置，其他卡片自动让位
  - **混合排序逻辑**: 
    - 新建/近期修改文件自动置顶
    - 支持用户手动拖拽自定义顺序
    - 未手动排序文件按时间倒序排列
  - **持久化**: 文件夹自定义顺序保存至 `localStorage`

- [x] **全功能文件拖放**
  - 支持文件/文件夹拖入子文件夹
  - 支持拖入根目录（拖至侧边栏空白处或根节点）
  - 拖拽时的准确高亮反馈

### B. 响应式与专注模式
- [x] **渐进式响应布局**
  - **宽屏 (>1000px)**: 完整三栏布局 (侧边栏 + 卡片/编辑 + Chat)
  - **中屏 (800-1000px)**: 自动隐藏右侧 Chat 栏，保留两栏
  - **窄屏 (<800px)**: 自动进入专注模式 (仅保留中间编辑区)
  
- [x] **专注模式增强**
  - **自动与手动**: 
    - 支持手动并切换 (`manualFocusMode`)
    - 窗口缩小时自动触发 (`autoHideLeft`/`autoHideRight`)
    - 自动模式下点击按钮可临时恢复右侧 Chat 栏
  - **性能优化**: 进入专注模式自动卸载 LLM 模型释放内存，退出时自动重载
  - **窗口控制**: 自动模式下点击"专注"按钮可智能调整窗口宽度至 1000px

### C. UI/UX 细节打磨
- [x] **视觉美化**
  - 全局滚动条微调 (4px 极细风格，静止时超淡，悬停时可见)
  - 侧边栏底部布局优化：新增**设置入口** (⚙️ 图标)，优化"断开连接"按钮
  - 移除顶部渐变遮罩 (尝试后移除，保持界面清爽)
  
- [x] **Bug 修复与改进**
  - 修复根目录选中高亮逻辑
  - 调整 Electron 窗口最小尺寸限制 (1000x700 -> 400x300) 以支持极致专注模式
  - 优化 IPC 通信，新增窗口尺寸控制 API

---



## ✅ Phase 2: 数据核心 (已完成)

### A. 智能文件系统

- [x] **首次启动引导** (`Onboarding.tsx`)
  - 全屏引导页，让用户选择笔记根目录
  - 使用 `electron-store` 持久化 vault 路径

- [x] **IPC 通信层** (`main.ts`, `preload.ts`)
  - 完整的文件系统 API (读/写/创建/删除/重命名)
  - `chokidar` 实时监听文件变化
  - 自动忽略 `.DS_Store`, `.git`, `node_modules`, `.zennote`

- [x] **递归文件树** (`FileTree.tsx`)
  - 文件夹展开/收起
  - 选中态高亮
  - 只显示 `.txt` 和 `.md` 文件

- [x] **格式热切换**
  - `.txt` ↔ `.md` 一键切换
  - 内容保持不变

### B. 聊天持久化 (Sidecar 模式)

- [x] **存储策略**
  - 隐藏目录: `.zennote/chats/`
  - 文件路径 Base64 编码作为 Key
  - JSON 格式存储聊天记录

- [x] **自动同步**
  - 打开文件时自动加载聊天记录
  - AI 回复后自动保存

### C. 上下文桥接 (Context Bridge)

- [x] **上下文注入**
  - 读取当前编辑文件内容 (限制 4000 字符)
  - 动态构建 System Prompt
  - AI 可以理解文件内容

- [x] **视觉反馈**
  - `ContextIndicator` 显示 "👁️ Reading: [文件名]"
  - 欢迎消息动态变化

### D. 实时心跳检测

- [x] **轮询机制**
  - 3 秒间隔检测 Ollama 状态
  - 连续 2 次失败触发降级

- [x] **热切换状态机**
  - Ollama 离线 → 自动切换 WebLLM
  - Ollama 上线 → 自动切换回 Ollama

- [x] **Toast 通知**
  - 引擎切换时显示浮动通知
  - 优雅的进入/退出动画

---

## ✅ Phase 1: 双模 AI 引擎 (已完成)

- [x] 项目初始化 (Electron + Vite + React)
- [x] macOS vibrancy 窗口效果
- [x] LLM 服务抽象层
- [x] Ollama 自动检测
- [x] WebLLM 降级支持
- [x] iMessage 风格聊天界面

---

## 📁 项目结构 (Phase 2)

```
禅意笔记本/
├── electron/
│   ├── main.ts           # IPC + chokidar + electron-store
│   └── preload.ts        # contextBridge API
├── src/
│   ├── components/
│   │   ├── Onboarding.tsx      # 首次启动引导
│   │   ├── FileTree.tsx        # 递归文件树
│   │   ├── Toast.tsx           # 通知系统
│   │   ├── ContextIndicator.tsx # 上下文指示器
│   │   ├── ChatPanel.tsx       # 聊天面板
│   │   ├── StatusIndicator.tsx # 状态指示器
│   │   └── Editor.tsx          # 文本编辑器
│   ├── hooks/
│   │   ├── useFileSystem.ts    # 文件系统 Hook
│   │   └── useLLM.ts           # LLM 核心 Hook
│   ├── services/
│   │   ├── types.ts            # 类型定义
│   │   ├── OllamaService.ts    # Ollama 客户端
│   │   ├── WebLLMService.ts    # WebLLM 封装
│   │   └── llm.worker.ts       # Web Worker
│   └── styles/
│       └── index.css           # 全局样式
├── package.json
└── CHANGELOG.md
```

---

## 📝 版本历史

### v0.4.0-beta (2025-12-17)

**新增**
- AI 状态呼吸灯指示器（替代静态大脑图标）
- 模型加载进度条（同一行布局）
- AI 思考状态提示（"正在思考中..."）
- 深色模式单色配色方案

**改进**
- 模型选择下拉菜单使用 Portal 渲染，修复层级遮挡
- 下拉菜单相对于 Chat 面板居中定位
- 下拉菜单自适应宽度
- 响应式隐藏模型标签（窄窗口时）
- 修复深色模式文字颜色可见性
- 加载状态改为中文显示

---

### v0.3.0-beta (2025-12-16)

**新增**
- 卡片网格视图 (iOS 风格)
- 智能拖拽排序 (支持自动/手动混合排序)
- 响应式布局 (自动专注模式)
- 专注模式增强 (智能显隐侧边栏)
- 设置入口
- 文件/文件夹全功能拖放

**改进**
- 滚动条样式优化
- 根目录高亮逻辑修复
- 窗口最小尺寸调整
- 拖拽视觉反馈优化

---

### v0.2.0-alpha (2024-12-14)

**新增**
- 首次启动引导页
- 递归文件树
- 文件实时监听 (chokidar)
- 聊天记录持久化 (Sidecar 模式)
- 上下文注入 (AI 可读取当前文件)
- 心跳检测 (实时 Ollama 状态监测)
- Toast 通知系统
- 格式热切换 (.txt ↔ .md)

**改进**
- 重构 `useLLM` Hook
- 添加自动保存 (1秒防抖)
- 改进错误处理和日志

---

### v0.1.0-alpha (2024-12-14)

**新增**
- 初始化项目结构
- 双模 AI 引擎架构
- macOS 原生视觉风格

---

## ✅ Phase 4: 设置中心与个性化 (已完成)

### A. 外观与风格
- [x] **多主题切换**
  - 浅色模式 (Light)
  - 深色模式 (Dark)
  - 禅意茶色 (Tea/Sepia)
- [x] **字体与排版**
  - 字体选择：宋体 (Serif) / 苹果系统字体 (Sans-serif)
  - 界面字体大小调节 (12-18px)

### B. Ollama 高级配置
- [x] **连接设置**
  - 自定义 API 地址 (默认 `http://localhost:11434`)
  - 连接连通性测试按钮

### C. AI 引擎策略
- [x] **模型优先级控制**
  - 拨杆开关：优先使用外部 Ollama / 优先使用内置 WebLLM
  - 自动降级策略的开关控制

### D. 角色设定与微调
- [x] **系统提示词 (System Prompt)**
  - 全局前置提示词配置
  - 提示词模板管理 (最多 5 个)
### E. 清理缓存按钮
- [ ] **清理缓存按钮**
  - 清理 `chats` 目录下的所有聊天记录
  - 清理 排序和标记颜色的缓存记录
  - 清理 AI 下载模型

### F. UI/UX 优化 (2025-12-17)
- [x] **模型选择下拉菜单**
  - 使用 React Portal 渲染到 body，修复层级遮挡问题
  - 下拉菜单相对于右侧 Chat 面板居中定位
  - 自适应宽度，根据内容自动调整
  - 响应式隐藏：窗口变窄时隐藏模型大小和内置标签

- [x] **AI 状态呼吸灯指示器**
  - 替换静态大脑图标为动态呼吸灯
  - 🔵 空闲状态：蓝色呼吸灯（固定颜色，不跟随主题）
  - 🔴 活跃状态：红色呼吸灯（生成中/加载模型中）
  - 加载模型时显示中文"加载模型中" + 进度条（同一行布局）
  - AI 回复时显示"正在思考中..."，隐藏模型选择器

- [x] **深色模式优化**
  - 修复深色模式下文字颜色可见性问题
  - 深色模式控件改为单色配色（灰色调），与茶色模式风格一致

---

## 🛠️ 开发命令

```bash
# 安装依赖
npm install

# 启动开发服务器
npm run dev

# 构建生产版本
npm run build
```

---

## 🐛 已知问题

1. WebGPU 兼容性可能因 Mac 机型而异
2. 首次加载 WebLLM 模型需要下载权重文件 (~300MB)
3. 需要手动安装 Ollama 才能使用本地模型

---

## ⚠️ 开发备忘

### `release/mac-arm64` 目录 (待清理)

> [!CAUTION]
> 该目录包含 **未完成的编译产物**，体积约 7.2GB，请勿使用！

- **创建时间**: 2025-12-18（Windows 编译时顺带生成）
- **问题**: 编译过程中途停止，bundled 模型未正确处理导致体积异常
- **建议**: 可安全删除以释放磁盘空间；需要 Mac 版本请使用 `.dmg` 文件或重新编译
