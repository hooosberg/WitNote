<p align="center">
  <img src="src/icon/æ™ºç®€icon æ‹·è´.png" alt="WitNote" width="128" height="128">
</p>

# WitNote (æ™ºç®€ç¬”è®°æœ¬)

> **Smart Core, Simple Form**
> *å¤§æ™ºè‹¥ç®€ï¼Œè½ç¬”ç”ŸèŠ±*

[English](README.md) | [ä¸­æ–‡](README_zh.md)

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Platform](https://img.shields.io/badge/platform-macOS-lightgrey.svg)]()
[![Apple Silicon](https://img.shields.io/badge/Apple%20Silicon-M1%20|%20M2%20|%20M3%20|%20M4-green.svg)]()

**WitNote** is a local-first AI writing companion for macOS.
We pack a powerful **dual AI engine** into an ultra-minimalist **native card interface**. No cloud dependency, no privacy concerns â€” intelligence made lightweight.

![Local AI](src/pic/æœ¬åœ°ai.png)

---

## ğŸŒŸ Core Philosophy

- **Smart**: Dual-engine AI
  - **Primary**: Auto-connects to local Ollama for full power
  - **Portable**: Built-in WebLLM browser model, ready out of the box
- **Simple**: No complexity
  - iOS-style card management, drag to organize
  - Smart focus mode â€” window narrows, editor simplifies
- **Secure**: Data sovereignty
  - 100% local storage. Your thoughts belong only to you.

---

## âœ¨ Features

- ğŸ“ **Pure Local Notes** â€” Choose any folder as your notes vault, supports `.txt` and `.md`
- ğŸ¤– **Dual AI Engine** â€” WebLLM (lightweight built-in) + Ollama (powerful external)
- ğŸ¨ **Multiple Themes** â€” Light / Dark / Zen Tea
- ğŸ—‚ï¸ **Card Grid View** â€” iOS-style with drag-and-drop sorting
- ğŸ” **Context Aware** â€” AI can directly read your current article
- ğŸ¯ **Focus Mode** â€” Auto-switches when window narrows
- ğŸŒ **Internationalization** â€” English and Chinese support

---

## ğŸš€ Quick Start

### Installation

Download the latest DMG installer from [Releases](https://github.com/hooosberg/WitNote/releases).

**Recommended Platform**: Apple Silicon (M1 / M2 / M3 / M4) Mac devices

### Development

```bash
# Clone the repository
git clone https://github.com/hooosberg/WitNote.git
cd WitNote

# Install dependencies
npm install

# Start development server
npm run dev

# Build production version
npm run build
```

---

## ğŸ”§ AI Engine Configuration

### WebLLM (Built-in)
Ready to use out of the box. The lightweight model downloads automatically on first use.

### Ollama (Recommended)
For more powerful AI capabilities, install [Ollama](https://ollama.com):

```bash
# After installing Ollama, download recommended models
ollama pull qwen2.5:0.5b
# Or a larger model
ollama pull qwen2.5:3b
```

The app automatically detects local Ollama service and prioritizes it.

---

## ğŸ“¸ Screenshots

![Multilingual Support](src/pic/å¤šè¯­è¨€.png)
![Dark Mode](src/pic/æ·±è‰²æ¨¡å¼.png)
![Smart Engine Switching](src/pic/æ™ºèƒ½å¼•æ“åˆ‡æ¢.png)

---

## ğŸ“„ License

MIT License

---

## ğŸ‘¨â€ğŸ’» Developer

**hooosberg**

ğŸ“§ [zikedece@proton.me](mailto:zikedece@proton.me)

ğŸ”— [https://github.com/hooosberg/WitNote](https://github.com/hooosberg/WitNote)

---

<p align="center">
  <i>Smart Core, Simple Form</i>
</p>
