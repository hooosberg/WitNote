/**
 * useLLM Hook
 * æ ¸å¿ƒï¼šåŒå¼•æ“ç®¡ç†ã€å¿ƒè·³æ£€æµ‹ã€ä¸Šä¸‹æ–‡æ³¨å…¥ã€èŠå¤©æŒä¹…åŒ–
 */

import { useState, useEffect, useCallback, useRef } from 'react';
import {
    LLMProviderType,
    LLMMessage,
    ChatMessage,
    LLMStatus,
    LoadProgress,
    OllamaModel,
    DEFAULT_WEBLLM_MODEL,
    SYSTEM_PROMPT
} from '../services/types';
import { OllamaService } from '../services/OllamaService';
import { WebLLMService } from '../services/WebLLMService';

// å¿ƒè·³æ£€æµ‹é—´éš” (æ¯«ç§’)
const HEARTBEAT_INTERVAL = 5000;
// è¿ç»­å¤±è´¥æ¬¡æ•°é˜ˆå€¼
const HEARTBEAT_FAIL_THRESHOLD = 2;
// ä¸Šä¸‹æ–‡æœ€å¤§é•¿åº¦
const MAX_CONTEXT_LENGTH = 4000;

// å¼•æ“åˆ‡æ¢äº‹ä»¶
export type EngineChangeEvent = {
    from: LLMProviderType;
    to: LLMProviderType;
    reason: 'heartbeat' | 'manual';
};

export interface UseLLMReturn {
    // çŠ¶æ€
    providerType: LLMProviderType;
    status: LLMStatus;
    modelName: string;
    loadProgress: LoadProgress | null;
    errorMessage: string | null;

    // Ollama ç›¸å…³
    ollamaModels: OllamaModel[];
    selectedOllamaModel: string;
    setSelectedOllamaModel: (model: string) => void;

    // èŠå¤©ç›¸å…³
    messages: ChatMessage[];
    isGenerating: boolean;

    // ä¸Šä¸‹æ–‡ç›¸å…³
    contextType: 'file' | 'folder' | null;
    activeFilePath: string | null;
    activeFileName: string | null;
    activeFileContent: string | null;
    activeFolderName: string | null;
    activeFolderFiles: string[];
    setActiveFileContext: (path: string | null, name: string | null, content: string | null) => void;
    setActiveFolderContext: (name: string | null, files: string[]) => void;

    // æ–¹æ³•
    sendMessage: (content: string) => Promise<void>;
    abortGeneration: () => void;
    clearMessages: () => void;
    setMessages: (messages: ChatMessage[]) => void;
    retryDetection: () => void;
    loadChatHistory: (filePath: string) => Promise<void>;

    // äº‹ä»¶
    onEngineChange: (callback: (event: EngineChangeEvent) => void) => void;
}

// ç”Ÿæˆå”¯ä¸€ ID
function generateId(): string {
    return `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
}

export function useLLM(): UseLLMReturn {
    // æä¾›è€…çŠ¶æ€
    const [providerType, setProviderType] = useState<LLMProviderType>('webllm');
    const [status, setStatus] = useState<LLMStatus>('detecting');
    const [modelName, setModelName] = useState<string>('');
    const [loadProgress, setLoadProgress] = useState<LoadProgress | null>(null);
    const [errorMessage, setErrorMessage] = useState<string | null>(null);

    // Ollama çŠ¶æ€
    const [ollamaModels, setOllamaModels] = useState<OllamaModel[]>([]);
    const [selectedOllamaModel, setSelectedOllamaModel] = useState<string>('');

    // èŠå¤©çŠ¶æ€
    const [messages, setMessages] = useState<ChatMessage[]>([]);
    const [isGenerating, setIsGenerating] = useState(false);

    // ä¸Šä¸‹æ–‡çŠ¶æ€
    const [contextType, setContextType] = useState<'file' | 'folder' | null>(null);
    const [activeFilePath, setActiveFilePath] = useState<string | null>(null);
    const [activeFileName, setActiveFileName] = useState<string | null>(null);
    const [activeFileContent, setActiveFileContent] = useState<string | null>(null);
    const [activeFolderName, setActiveFolderName] = useState<string | null>(null);
    const [activeFolderFiles, setActiveFolderFiles] = useState<string[]>([]);

    // æœåŠ¡å¼•ç”¨
    const ollamaServiceRef = useRef<OllamaService | null>(null);
    const webllmServiceRef = useRef<WebLLMService | null>(null);

    // å¿ƒè·³æ£€æµ‹å¼•ç”¨
    const heartbeatRef = useRef<NodeJS.Timeout | null>(null);
    const heartbeatFailCountRef = useRef(0);

    // ä½¿ç”¨ ref è·Ÿè¸ªæœ€æ–°çŠ¶æ€ï¼ˆè§£å†³é—­åŒ…é—®é¢˜ï¼‰
    const providerTypeRef = useRef<LLMProviderType>(providerType);
    const statusRef = useRef<LLMStatus>(status);

    // åŒæ­¥çŠ¶æ€åˆ° ref
    useEffect(() => {
        providerTypeRef.current = providerType;
    }, [providerType]);

    useEffect(() => {
        statusRef.current = status;
    }, [status]);

    // å¼•æ“åˆ‡æ¢å›è°ƒ
    const engineChangeCallbackRef = useRef<((event: EngineChangeEvent) => void) | null>(null);

    /**
     * æ³¨å†Œå¼•æ“åˆ‡æ¢å›è°ƒ
     */
    const onEngineChange = useCallback((callback: (event: EngineChangeEvent) => void) => {
        engineChangeCallbackRef.current = callback;
    }, []);

    /**
     * è§¦å‘å¼•æ“åˆ‡æ¢äº‹ä»¶
     */
    const emitEngineChange = useCallback((event: EngineChangeEvent) => {
        console.log('ğŸ”„ å¼•æ“åˆ‡æ¢:', event.from, '->', event.to);
        if (engineChangeCallbackRef.current) {
            engineChangeCallbackRef.current(event);
        }
    }, []);

    /**
     * è®¾ç½®æ´»åŠ¨æ–‡ä»¶ä¸Šä¸‹æ–‡
     */
    const setActiveFileContext = useCallback((
        path: string | null,
        name: string | null,
        content: string | null
    ) => {
        setContextType(path ? 'file' : null);
        setActiveFilePath(path);
        setActiveFileName(name);
        setActiveFileContent(content);
        // æ¸…ç©ºæ–‡ä»¶å¤¹ä¸Šä¸‹æ–‡
        setActiveFolderName(null);
        setActiveFolderFiles([]);
    }, []);

    /**
     * è®¾ç½®æ´»åŠ¨æ–‡ä»¶å¤¹ä¸Šä¸‹æ–‡
     */
    const setActiveFolderContext = useCallback((
        name: string | null,
        files: string[]
    ) => {
        // è°ƒç”¨æ­¤å‡½æ•°å³è¡¨ç¤ºé€‰ä¸­äº†æ–‡ä»¶å¤¹ï¼ˆåŒ…æ‹¬ç©ºæ–‡ä»¶å¤¹å’Œæ ¹ç›®å½•ï¼‰
        setContextType('folder');
        setActiveFolderName(name);
        setActiveFolderFiles(files);
        // æ¸…ç©ºæ–‡ä»¶ä¸Šä¸‹æ–‡
        setActiveFilePath(null);
        setActiveFileName(null);
        setActiveFileContent(null);
    }, []);

    /**
     * åˆå§‹åŒ– WebLLM
     */
    const initializeWebLLM = useCallback(async () => {
        console.log('ğŸ”µ åˆå§‹åŒ– WebLLM...');
        setProviderType('webllm');
        setModelName(DEFAULT_WEBLLM_MODEL);
        setStatus('loading');

        const webllmService = new WebLLMService();

        webllmService.setProgressCallback((progress) => {
            setLoadProgress(progress);
        });

        try {
            await webllmService.initialize();
            webllmServiceRef.current = webllmService;
            setStatus('ready');
            setLoadProgress(null);
            console.log('âœ… WebLLM åˆå§‹åŒ–æˆåŠŸ');
        } catch (error) {
            console.error('âŒ WebLLM åˆå§‹åŒ–å¤±è´¥:', error);
            const errMsg = error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯';
            setErrorMessage(`WebLLM åˆå§‹åŒ–å¤±è´¥: ${errMsg}`);
            setStatus('error');
        }
    }, []);

    /**
     * åˆå§‹åŒ– Ollama
     */
    const initializeOllama = useCallback(async (models: OllamaModel[]) => {
        console.log('ğŸŸ¢ åˆå§‹åŒ– Ollama...');
        setOllamaModels(models);
        setSelectedOllamaModel(models[0].name);
        setProviderType('ollama');
        setModelName(models[0].name);

        const ollamaService = new OllamaService(models[0].name);
        try {
            await ollamaService.initialize();
            ollamaServiceRef.current = ollamaService;
            setStatus('ready');
            console.log('âœ… Ollama åˆå§‹åŒ–æˆåŠŸ');
        } catch (error) {
            console.error('âŒ Ollama åˆå§‹åŒ–å¤±è´¥:', error);
            throw error;
        }
    }, []);

    /**
     * å¿ƒè·³æ£€æµ‹ - å®æ—¶ç›‘æµ‹ Ollama çŠ¶æ€
     */
    const startHeartbeat = useCallback(() => {
        if (heartbeatRef.current) {
            clearInterval(heartbeatRef.current);
        }

        console.log('ğŸ’“ å¯åŠ¨å¿ƒè·³æ£€æµ‹ (æ¯ 5 ç§’)');

        heartbeatRef.current = setInterval(async () => {
            const models = await OllamaService.detect();
            const currentProvider = providerTypeRef.current;
            const currentStatus = statusRef.current;

            console.log(`ğŸ’“ å¿ƒè·³: provider=${currentProvider}, status=${currentStatus}, ollama=${models ? 'online' : 'offline'}`);

            if (models && models.length > 0) {
                // Ollama åœ¨çº¿
                heartbeatFailCountRef.current = 0;

                if (currentProvider === 'webllm' && currentStatus === 'ready') {
                    // ä» WebLLM åˆ‡æ¢åˆ° Ollama
                    console.log('ğŸ’š æ£€æµ‹åˆ° Ollamaï¼Œè‡ªåŠ¨åˆ‡æ¢...');

                    // åœæ­¢ WebLLM
                    if (webllmServiceRef.current) {
                        webllmServiceRef.current.destroy();
                        webllmServiceRef.current = null;
                    }

                    try {
                        await initializeOllama(models);
                        emitEngineChange({ from: 'webllm', to: 'ollama', reason: 'heartbeat' });
                    } catch (e) {
                        console.error('åˆ‡æ¢åˆ° Ollama å¤±è´¥:', e);
                    }
                }
            } else {
                // Ollama ç¦»çº¿
                heartbeatFailCountRef.current++;
                console.log(`ğŸ’” Ollama ç¦»çº¿, å¤±è´¥æ¬¡æ•°: ${heartbeatFailCountRef.current}`);

                if (currentProvider === 'ollama' && heartbeatFailCountRef.current >= HEARTBEAT_FAIL_THRESHOLD) {
                    // ä» Ollama åˆ‡æ¢åˆ° WebLLM
                    console.log('ğŸ’” Ollama æŒç»­ç¦»çº¿ï¼Œè‡ªåŠ¨é™çº§åˆ° WebLLM...');

                    ollamaServiceRef.current = null;
                    emitEngineChange({ from: 'ollama', to: 'webllm', reason: 'heartbeat' });

                    await initializeWebLLM();
                    heartbeatFailCountRef.current = 0;
                }
            }
        }, HEARTBEAT_INTERVAL);
    }, [initializeOllama, initializeWebLLM, emitEngineChange]);

    /**
     * æ£€æµ‹å¹¶åˆå§‹åŒ– LLM å¼•æ“
     */
    const detectAndInitialize = useCallback(async () => {
        console.log('ğŸ” å¼€å§‹æ£€æµ‹ LLM å¼•æ“...');
        setStatus('detecting');
        setLoadProgress(null);
        setErrorMessage(null);

        const models = await OllamaService.detect();

        if (models && models.length > 0) {
            console.log('âœ… Ollama Detected: YES');
            console.log(`ğŸ“‹ å¯ç”¨æ¨¡å‹: ${models.map(m => m.name).join(', ')}`);

            try {
                await initializeOllama(models);
            } catch {
                console.log('âš ï¸ Ollama åˆå§‹åŒ–å¤±è´¥ï¼Œé™çº§åˆ° WebLLM');
                await initializeWebLLM();
            }
        } else {
            console.log('âš ï¸ Ollama Detected: NO, ä½¿ç”¨ WebLLM');
            await initializeWebLLM();
        }

        // å¯åŠ¨å¿ƒè·³æ£€æµ‹
        startHeartbeat();
    }, [initializeOllama, initializeWebLLM, startHeartbeat]);

    /**
     * æ„å»ºä¸Šä¸‹æ–‡å¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯
     */
    const buildContextPrompt = useCallback((userInput: string): string => {
        // æ–‡ä»¶ä¸Šä¸‹æ–‡
        if (activeFileContent && activeFileName) {
            const truncatedContent = activeFileContent.slice(0, MAX_CONTEXT_LENGTH);
            const isTruncated = activeFileContent.length > MAX_CONTEXT_LENGTH;

            return `${SYSTEM_PROMPT}

[ä¸Šä¸‹æ–‡: ç”¨æˆ·æ­£åœ¨ç¼–è¾‘ "${activeFileName}"]
æ–‡ä»¶å†…å®¹:
"""
${truncatedContent}${isTruncated ? '\n... (å†…å®¹å·²æˆªæ–­)' : ''}
"""

ç”¨æˆ·é—®é¢˜: ${userInput}`;
        }

        // æ–‡ä»¶å¤¹ä¸Šä¸‹æ–‡
        if (activeFolderName && activeFolderFiles.length > 0) {
            const fileList = activeFolderFiles.slice(0, 20).map(f => `- ${f}`).join('\n');
            const hasMore = activeFolderFiles.length > 20;

            return `${SYSTEM_PROMPT}

[ä¸Šä¸‹æ–‡: ç”¨æˆ·æ­£åœ¨æµè§ˆæ–‡ä»¶å¤¹ "${activeFolderName}"]
è¯¥æ–‡ä»¶å¤¹åŒ…å«ä»¥ä¸‹æ–‡ä»¶:
${fileList}${hasMore ? '\n... (æ›´å¤šæ–‡ä»¶)' : ''}

ç”¨æˆ·é—®é¢˜: ${userInput}`;
        }

        return userInput;
    }, [activeFileContent, activeFileName, activeFolderName, activeFolderFiles]);

    /**
     * å‘é€æ¶ˆæ¯
     */
    const sendMessage = useCallback(async (content: string) => {
        if (!content.trim() || isGenerating) return;
        if (status !== 'ready') {
            console.warn('âš ï¸ LLM æœåŠ¡æœªå°±ç»ª');
            return;
        }

        // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        const userMessage: ChatMessage = {
            id: generateId(),
            role: 'user',
            content: content.trim(),
            timestamp: Date.now()
        };

        // æ·»åŠ ç©ºçš„åŠ©æ‰‹æ¶ˆæ¯
        const assistantMessage: ChatMessage = {
            id: generateId(),
            role: 'assistant',
            content: '',
            timestamp: Date.now(),
            isStreaming: true
        };

        const newMessages = [...messages, userMessage, assistantMessage];
        setMessages(newMessages);
        setIsGenerating(true);

        // æ„å»ºå†å²æ¶ˆæ¯ï¼ˆå¸¦ä¸Šä¸‹æ–‡ï¼‰
        const historyMessages: LLMMessage[] = messages.map(m => ({
            role: m.role,
            content: m.content
        }));

        // ä¸ºç”¨æˆ·æ¶ˆæ¯æ·»åŠ ä¸Šä¸‹æ–‡
        const contextEnhancedInput = buildContextPrompt(content.trim());
        historyMessages.push({ role: 'user', content: contextEnhancedInput });

        // æµå¼å›è°ƒ
        const onToken = (token: string) => {
            setMessages(prev => {
                const updated = [...prev];
                const lastMsg = updated[updated.length - 1];
                if (lastMsg && lastMsg.role === 'assistant') {
                    lastMsg.content += token;
                }
                return updated;
            });
        };

        const onComplete = async () => {
            setMessages(prev => {
                const updated = [...prev];
                const lastMsg = updated[updated.length - 1];
                if (lastMsg) {
                    lastMsg.isStreaming = false;
                }
                return updated;
            });
            setIsGenerating(false);

            // è‡ªåŠ¨ä¿å­˜èŠå¤©è®°å½•
            if (activeFilePath && window.chat) {
                try {
                    const finalMessages = [...newMessages];
                    finalMessages[finalMessages.length - 1].isStreaming = false;
                    await window.chat.save(activeFilePath, finalMessages);
                    console.log('ğŸ’¾ èŠå¤©è®°å½•å·²ä¿å­˜');
                } catch (error) {
                    console.error('ä¿å­˜èŠå¤©è®°å½•å¤±è´¥:', error);
                }
            }
        };

        const onError = (error: Error) => {
            console.error('âŒ ç”Ÿæˆé”™è¯¯:', error);
            setMessages(prev => {
                const updated = [...prev];
                const lastMsg = updated[updated.length - 1];
                if (lastMsg && lastMsg.role === 'assistant') {
                    lastMsg.content = `âŒ ç”Ÿæˆå‡ºé”™: ${error.message}`;
                    lastMsg.isStreaming = false;
                }
                return updated;
            });
            setIsGenerating(false);
        };

        // è°ƒç”¨å¯¹åº”æœåŠ¡
        try {
            if (providerType === 'ollama' && ollamaServiceRef.current) {
                await ollamaServiceRef.current.streamChat(historyMessages, onToken, onComplete, onError);
            } else if (providerType === 'webllm' && webllmServiceRef.current) {
                await webllmServiceRef.current.streamChat(historyMessages, onToken, onComplete, onError);
            } else {
                throw new Error('æ²¡æœ‰å¯ç”¨çš„ LLM æœåŠ¡');
            }
        } catch (error) {
            onError(error instanceof Error ? error : new Error('æœªçŸ¥é”™è¯¯'));
        }
    }, [messages, isGenerating, status, providerType, activeFilePath, buildContextPrompt]);

    /**
     * åŠ è½½èŠå¤©å†å²
     */
    const loadChatHistory = useCallback(async (filePath: string) => {
        if (!window.chat) return;
        try {
            const history = await window.chat.load(filePath) as ChatMessage[];
            setMessages(history);
            console.log(`ğŸ“‚ åŠ è½½èŠå¤©è®°å½•: ${history.length} æ¡æ¶ˆæ¯`);
        } catch (error) {
            console.error('åŠ è½½èŠå¤©è®°å½•å¤±è´¥:', error);
            setMessages([]);
        }
    }, []);

    /**
     * ä¸­æ­¢ç”Ÿæˆ
     */
    const abortGeneration = useCallback(() => {
        if (providerType === 'ollama' && ollamaServiceRef.current) {
            ollamaServiceRef.current.abort();
        } else if (providerType === 'webllm' && webllmServiceRef.current) {
            webllmServiceRef.current.abort();
        }
        setIsGenerating(false);
    }, [providerType]);

    /**
     * æ¸…ç©ºæ¶ˆæ¯
     */
    const clearMessages = useCallback(() => {
        setMessages([]);
    }, []);

    /**
     * é‡æ–°æ£€æµ‹
     */
    const retryDetection = useCallback(() => {
        detectAndInitialize();
    }, [detectAndInitialize]);

    /**
     * åˆ‡æ¢ Ollama æ¨¡å‹
     */
    const handleSetSelectedOllamaModel = useCallback((model: string) => {
        setSelectedOllamaModel(model);
        setModelName(model);

        if (ollamaServiceRef.current) {
            ollamaServiceRef.current.setModel(model);
        }
    }, []);

    // å¯åŠ¨æ—¶æ£€æµ‹
    useEffect(() => {
        detectAndInitialize();

        return () => {
            if (heartbeatRef.current) {
                clearInterval(heartbeatRef.current);
            }
            if (webllmServiceRef.current) {
                webllmServiceRef.current.destroy();
            }
        };
    }, []);

    return {
        providerType,
        status,
        modelName,
        loadProgress,
        errorMessage,
        ollamaModels,
        selectedOllamaModel,
        setSelectedOllamaModel: handleSetSelectedOllamaModel,
        messages,
        isGenerating,
        contextType,
        activeFilePath,
        activeFileName,
        activeFileContent,
        activeFolderName,
        activeFolderFiles,
        setActiveFileContext,
        setActiveFolderContext,
        sendMessage,
        abortGeneration,
        clearMessages,
        setMessages,
        retryDetection,
        loadChatHistory,
        onEngineChange
    };
}

export default useLLM;
