/**
 * useLLM Hook
 * Ollama-only æ¶æ„ï¼šç®€åŒ–çš„æœ¬åœ°AIå¼•æ“ç®¡ç†
 */

import { useState, useEffect, useCallback, useRef } from 'react';
import {
    LLMMessage,
    ChatMessage,
    LLMStatus,
    LoadProgress,
    OllamaModel,
    getDefaultSystemPrompt,
    RECOMMENDED_MODELS
} from '../services/types';
import { OllamaService } from '../services/OllamaService';
import { useSettings } from './useSettings';
import { getCurrentLanguage } from '../i18n';

// ä¸Šä¸‹æ–‡æœ€å¤§é•¿åº¦
const MAX_CONTEXT_LENGTH = 4000;

export interface UseLLMReturn {
    // çŠ¶æ€
    status: LLMStatus;
    modelName: string;
    loadProgress: LoadProgress | null;
    errorMessage: string | null;

    // Ollama æ¨¡å‹
    ollamaModels: OllamaModel[];
    selectedOllamaModel: string;
    setSelectedOllamaModel: (model: string) => void;

    // èŠå¤©ç›¸å…³
    messages: ChatMessage[];
    isGenerating: boolean;

    // ä¸Šä¸‹æ–‡ç›¸å…³
    contextType: 'file' | 'folder' | null;
    activeFilePath: string | null;
    activeFileName: string | null;
    activeFileContent: string | null;
    activeFolderName: string | null;
    activeFolderFiles: string[];
    setActiveFileContext: (path: string | null, name: string | null, content: string | null) => void;
    setActiveFolderContext: (name: string | null, files: string[], previews?: Map<string, string>) => void;

    // æ–¹æ³•
    sendMessage: (content: string) => Promise<void>;
    abortGeneration: () => void;
    clearMessages: () => void;
    injectMessage: (role: 'system' | 'user' | 'assistant', content: string) => void;
    setMessages: (messages: ChatMessage[]) => void;
    retryDetection: () => void;
    loadChatHistory: (filePath: string) => Promise<ChatMessage[]>;
    unloadModel: () => void;

    // æ¨¡å‹ç®¡ç†
    refreshModels: () => Promise<void>;
    pullModel: (modelName: string) => Promise<void>;
    deleteModel: (modelName: string) => Promise<void>;
    cancelPull: (modelName?: string) => Promise<void>;
    downloadProgressMap: Map<string, { output: string; progress: number }>;
}

// å¯¼å‡ºæ¨èæ¨¡å‹ä¾›UIä½¿ç”¨
export { RECOMMENDED_MODELS };

// ç”Ÿæˆå”¯ä¸€ ID
function generateId(): string {
    return `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
}

export function useLLM(): UseLLMReturn {
    const { settings } = useSettings();
    // å¦‚æœç”¨æˆ·è®¾ç½®äº†è‡ªå®šä¹‰æç¤ºè¯åˆ™ä½¿ç”¨ï¼Œå¦åˆ™ä½¿ç”¨å†…ç½®é»˜è®¤æç¤ºè¯
    const userSystemPrompt = settings.systemPrompt;

    // çŠ¶æ€
    const [status, setStatus] = useState<LLMStatus>('detecting');
    const [modelName, setModelName] = useState<string>('');
    const [loadProgress, setLoadProgress] = useState<LoadProgress | null>(null);
    const [errorMessage, setErrorMessage] = useState<string | null>(null);

    // Ollama çŠ¶æ€
    const [ollamaModels, setOllamaModels] = useState<OllamaModel[]>([]);
    const [selectedOllamaModel, setSelectedOllamaModel] = useState<string>('');

    // æ¨¡å‹ç®¡ç†çŠ¶æ€ - ä½¿ç”¨ Map æ”¯æŒå¤šæ¨¡å‹å¹¶è¡Œä¸‹è½½
    const [downloadProgressMap, setDownloadProgressMap] = useState<Map<string, { output: string; progress: number }>>(new Map());

    // èŠå¤©çŠ¶æ€
    const [messages, setMessages] = useState<ChatMessage[]>([]);
    const [isGenerating, setIsGenerating] = useState(false);

    // ä¸Šä¸‹æ–‡çŠ¶æ€
    const [contextType, setContextType] = useState<'file' | 'folder' | null>(null);
    const [activeFilePath, setActiveFilePath] = useState<string | null>(null);
    const [activeFileName, setActiveFileName] = useState<string | null>(null);
    const [activeFileContent, setActiveFileContent] = useState<string | null>(null);
    const [activeFolderName, setActiveFolderName] = useState<string | null>(null);
    const [activeFolderFiles, setActiveFolderFiles] = useState<string[]>([]);
    const [filePreviews, setFilePreviews] = useState<Map<string, string>>(new Map());
    const [activeChatPath, setActiveChatPath] = useState<string | null>(null);
    const sessionChatCache = useRef<Map<string, ChatMessage[]>>(new Map());

    // æœåŠ¡å¼•ç”¨
    const ollamaServiceRef = useRef<OllamaService | null>(null);

    // ç›‘å¬ä¸‹è½½è¿›åº¦ - æŒ‰æ¨¡å‹ååˆ†åˆ«è¿½è¸ªè¿›åº¦
    useEffect(() => {
        if (!window.ollama) return;
        return window.ollama.onPullProgress((data) => {
            // ä» output ä¸­è§£æè¿›åº¦ç™¾åˆ†æ¯”ï¼Œä¾‹å¦‚ "pulling manifest" æˆ– "pulling sha256:xxx 50%"
            const percentMatch = data.output.match(/(\d+)%/);
            const progress = percentMatch ? parseInt(percentMatch[1], 10) : 0;
            setDownloadProgressMap(prev => {
                const next = new Map(prev);
                next.set(data.model, { output: data.output, progress });
                return next;
            });
        });
    }, []);

    /**
     * è®¾ç½®æ´»åŠ¨æ–‡ä»¶ä¸Šä¸‹æ–‡
     */
    const setActiveFileContext = useCallback((
        path: string | null,
        name: string | null,
        content: string | null
    ) => {
        setContextType(path ? 'file' : null);
        setActiveFilePath(path);
        setActiveFileName(name);
        setActiveFileContent(content);
        setActiveFolderName(null);
        setActiveFolderFiles([]);
    }, []);

    /**
     * è®¾ç½®æ´»åŠ¨æ–‡ä»¶å¤¹ä¸Šä¸‹æ–‡
     */
    const setActiveFolderContext = useCallback((
        name: string | null,
        files: string[],
        previews?: Map<string, string>
    ) => {
        setContextType('folder');
        setActiveFolderName(name);
        setActiveFolderFiles(files);
        setFilePreviews(previews || new Map());
        setActiveFilePath(null);
        setActiveFileName(null);
        setActiveFileContent(null);
    }, []);

    /**
     * åˆ·æ–°å·²å®‰è£…æ¨¡å‹åˆ—è¡¨
     */
    const refreshModels = useCallback(async () => {
        if (!window.ollama) return;
        try {
            const result = await window.ollama.listModels();
            if (result && result.success && Array.isArray(result.models)) {
                const mappedModels: OllamaModel[] = result.models.map((m: any) => ({
                    name: m.name,
                    size: parseInt(m.size) || 0,
                    digest: m.id,
                    modified_at: m.modified,
                    formattedSize: m.size
                }));
                setOllamaModels(mappedModels);
                console.log('ğŸ“¦ å·²å®‰è£…æ¨¡å‹åˆ—è¡¨:', mappedModels.map(m => m.name));
            }
        } catch (e) {
            console.error('åˆ·æ–°æ¨¡å‹åˆ—è¡¨å¤±è´¥:', e);
        }
    }, []);

    /**
     * ä¸‹è½½æ¨¡å‹
     */
    const pullModel = useCallback(async (modelName: string) => {
        if (!window.ollama) return;

        // è®¾ç½®åˆå§‹ä¸‹è½½çŠ¶æ€
        setDownloadProgressMap(prev => {
            const next = new Map(prev);
            next.set(modelName, { output: 'å¼€å§‹ä¸‹è½½...', progress: 0 });
            return next;
        });

        try {
            const result = await window.ollama.pullModel(modelName);
            if (result.success) {
                console.log(`âœ… æ¨¡å‹ ${modelName} ä¸‹è½½æˆåŠŸ`);
                await refreshModels();
            } else {
                throw new Error(result.output || 'ä¸‹è½½å¤±è´¥');
            }
        } catch (error) {
            console.error(`âŒ æ¨¡å‹ ${modelName} ä¸‹è½½å¤±è´¥:`, error);
            setErrorMessage(`ä¸‹è½½å¤±è´¥: ${error instanceof Error ? error.message : String(error)}`);
            setTimeout(() => setErrorMessage(null), 3000);
        } finally {
            // æ¸…é™¤è¯¥æ¨¡å‹çš„ä¸‹è½½è¿›åº¦
            setDownloadProgressMap(prev => {
                const next = new Map(prev);
                next.delete(modelName);
                return next;
            });
        }
    }, [refreshModels]);

    /**
     * åˆ é™¤æ¨¡å‹
     */
    const deleteModel = useCallback(async (modelName: string) => {
        if (!window.ollama) return;
        if (!confirm(`ç¡®å®šè¦åˆ é™¤æ¨¡å‹ ${modelName} å—ï¼Ÿ`)) return;

        try {
            const result = await window.ollama.deleteModel(modelName);
            if (result.success) {
                console.log(`ğŸ—‘ï¸ æ¨¡å‹ ${modelName} åˆ é™¤æˆåŠŸ`);
                await refreshModels();
                if (modelName === selectedOllamaModel) {
                    setSelectedOllamaModel(ollamaModels[0]?.name || '');
                }
            }
        } catch (error) {
            console.error(`âŒ æ¨¡å‹ ${modelName} åˆ é™¤å¤±è´¥:`, error);
        }
    }, [refreshModels, selectedOllamaModel, ollamaModels]);

    /**
     * å–æ¶ˆä¸‹è½½ - æ”¯æŒå–æ¶ˆç‰¹å®šæ¨¡å‹
     */
    const cancelPull = useCallback(async (modelName?: string) => {
        if (!window.ollama) return;

        try {
            const result = await window.ollama.cancelPull(modelName);
            if (result.success) {
                console.log(`ğŸ›‘ å·²å–æ¶ˆä¸‹è½½: ${result.cancelled}`);
                // æ¸…é™¤è¢«å–æ¶ˆæ¨¡å‹çš„ä¸‹è½½è¿›åº¦
                if (result.cancelled) {
                    // å¯èƒ½æ˜¯å¤šä¸ªæ¨¡å‹åï¼ˆé€—å·åˆ†éš”ï¼‰
                    const cancelledNames = result.cancelled.split(', ');
                    setDownloadProgressMap(prev => {
                        const next = new Map(prev);
                        cancelledNames.forEach(name => next.delete(name));
                        return next;
                    });
                } else {
                    // å¦‚æœæ²¡æœ‰è¿”å›å…·ä½“æ¨¡å‹åï¼Œæ¸…é™¤æ‰€æœ‰
                    setDownloadProgressMap(new Map());
                }
                await refreshModels();
            }
        } catch (error) {
            console.error('å–æ¶ˆä¸‹è½½å¤±è´¥:', error);
            // å¦‚æœæŒ‡å®šäº†æ¨¡å‹åï¼Œåªæ¸…é™¤è¯¥æ¨¡å‹
            if (modelName) {
                setDownloadProgressMap(prev => {
                    const next = new Map(prev);
                    next.delete(modelName);
                    return next;
                });
            } else {
                setDownloadProgressMap(new Map());
            }
        }
    }, [refreshModels]);

    /**
     * åˆå§‹åŒ– Ollama
     */
    const initializeOllama = useCallback(async (models: OllamaModel[]) => {
        console.log('ğŸŸ¢ åˆå§‹åŒ– Ollama...');
        setOllamaModels(models);

        // ä» localStorage æ¢å¤å·²ä¿å­˜çš„æ¨¡å‹é€‰æ‹©ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–æ— æ•ˆåˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡å‹
        const savedModel = localStorage.getItem('zen-selected-ollama-model');
        const modelToUse = savedModel && models.some(m => m.name === savedModel)
            ? savedModel
            : models[0].name;

        setSelectedOllamaModel(modelToUse);
        setModelName(modelToUse);

        const ollamaService = new OllamaService(modelToUse);
        try {
            await ollamaService.initialize();
            ollamaServiceRef.current = ollamaService;
            setStatus('ready');
            console.log('âœ… Ollama åˆå§‹åŒ–æˆåŠŸï¼Œä½¿ç”¨æ¨¡å‹:', modelToUse);
        } catch (error) {
            console.error('âŒ Ollama åˆå§‹åŒ–å¤±è´¥:', error);
            setErrorMessage('Ollama åˆå§‹åŒ–å¤±è´¥');
            setStatus('error');
        }
    }, []);

    /**
     * æ£€æµ‹å¹¶åˆå§‹åŒ–
     */
    const detectAndInitialize = useCallback(async () => {
        console.log('ğŸ” å¼€å§‹æ£€æµ‹ Ollama å¼•æ“...');
        setStatus('detecting');
        setLoadProgress(null);
        setErrorMessage(null);

        // å°è¯• HTTP æ£€æµ‹
        const httpModels = await OllamaService.detect();

        // å°è¯• IPC è·å–æ¨¡å‹åˆ—è¡¨
        let models: OllamaModel[] = [];
        if (window.ollama) {
            try {
                const listResult = await window.ollama.listModels();
                if (listResult && listResult.success && Array.isArray(listResult.models)) {
                    models = listResult.models.map((m: any) => ({
                        name: m.name,
                        size: 0,
                        digest: m.id,
                        modified_at: m.modified,
                        formattedSize: m.size
                    }));
                }
            } catch (e) {
                console.log('IPC listModels å¤±è´¥:', e);
            }
        }

        // åˆå¹¶ç»“æœ
        if (models.length === 0 && httpModels) {
            models = httpModels;
        }

        if (models.length > 0) {
            console.log('âœ… Ollama æ£€æµ‹æˆåŠŸï¼Œæ¨¡å‹æ•°:', models.length);
            await initializeOllama(models);
        } else {
            console.log('âš ï¸ æœªæ£€æµ‹åˆ° Ollama æœåŠ¡æˆ–æ¨¡å‹');
            setErrorMessage('æœªæ£€æµ‹åˆ° Ollama æœåŠ¡ã€‚è¯·ç¡®ä¿åº”ç”¨å·²æ­£ç¡®å¯åŠ¨ã€‚');
            setStatus('error');
        }
    }, [initializeOllama]);

    /**
     * è·å–ç³»ç»Ÿæç¤ºè¯
     * å¦‚æœç”¨æˆ·è®¾ç½®äº†è‡ªå®šä¹‰æç¤ºè¯åˆ™ä½¿ç”¨ï¼Œå¦åˆ™æ ¹æ®å½“å‰è¯­è¨€ä½¿ç”¨å†…ç½®é»˜è®¤æç¤ºè¯
     */
    const getSystemPrompt = useCallback(() => {
        if (userSystemPrompt && userSystemPrompt.trim()) {
            return userSystemPrompt.trim();
        }
        // æ ¹æ®å½“å‰è¯­è¨€è·å–é»˜è®¤æç¤ºè¯
        return getDefaultSystemPrompt(getCurrentLanguage());
    }, [userSystemPrompt]);

    /**
     * æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
     */
    const buildContextInfo = useCallback((): string | null => {
        if (activeFileContent && activeFileName) {
            const truncatedContent = activeFileContent.slice(0, MAX_CONTEXT_LENGTH);
            const isTruncated = activeFileContent.length > MAX_CONTEXT_LENGTH;
            return `ã€å½“å‰çŠ¶æ€ã€‘ç”¨æˆ·æ­£åœ¨ç¼–è¾‘æ–‡ç« ã€Œ${activeFileName}ã€

æ–‡ç« å†…å®¹:
"""
${truncatedContent}${isTruncated ? '\n... (å†…å®¹å·²æˆªæ–­)' : ''}
"""`;
        }

        if (activeFolderName && activeFolderFiles.length > 0) {
            const filesToShow = activeFolderFiles.slice(0, 20);
            const hasMore = activeFolderFiles.length > 20;
            const fileListWithPreviews = filesToShow.map((f, i) => {
                const preview = filePreviews.get(f);
                return preview ? `${i + 1}. ${f}ï¼š${preview}` : `${i + 1}. ${f}`;
            }).join('\n');

            return `ã€å½“å‰çŠ¶æ€ã€‘ç”¨æˆ·æ­£åœ¨æµè§ˆæ–‡ä»¶å¤¹ã€Œ${activeFolderName}ã€
ã€æ–‡ä»¶åˆ—è¡¨ã€‘å…± ${activeFolderFiles.length} ä¸ªï¼š
${fileListWithPreviews}${hasMore ? '\n... (æ›´å¤šæ–‡ä»¶)' : ''}`;
        }

        if (activeFolderFiles.length > 0) {
            const filesToShow = activeFolderFiles.slice(0, 30);
            const hasMore = activeFolderFiles.length > 30;
            const fileListWithPreviews = filesToShow.map((f, i) => {
                const preview = filePreviews.get(f);
                return preview ? `${i + 1}. ${f}ï¼š${preview}` : `${i + 1}. ${f}`;
            }).join('\n');

            return `ã€å½“å‰çŠ¶æ€ã€‘ç”¨æˆ·æ­£åœ¨æŸ¥çœ‹å…¨éƒ¨ç¬”è®°ï¼ˆæ ¹ç›®å½•ï¼‰
ã€æ–‡ä»¶åˆ—è¡¨ã€‘å…± ${activeFolderFiles.length} ç¯‡ï¼š
${fileListWithPreviews}${hasMore ? '\n... (æ›´å¤šæ–‡ç« )' : ''}`;
        }

        return null;
    }, [activeFileContent, activeFileName, activeFolderName, activeFolderFiles, filePreviews]);

    /**
     * æœç´¢æ–‡ä»¶
     */
    const searchFiles = useCallback((userMessage: string): string | null => {
        if (filePreviews.size === 0) return null;

        const searchIntentWords = ['æœ‰æ²¡æœ‰', 'æœ‰ä»€ä¹ˆ', 'å…³äº', 'æ‰¾', 'æœç´¢', 'æŸ¥', 'å“ªé‡Œ', 'å“ªä¸ª', 'å“ªäº›'];
        const hasSearchIntent = searchIntentWords.some(word => userMessage.includes(word));
        if (!hasSearchIntent) return null;

        const stopWords = ['æœ‰æ²¡æœ‰', 'æœ‰ä»€ä¹ˆ', 'å…³äº', 'çš„', 'å—', 'å‘¢', 'æ–‡ç« ', 'æ–‡ä»¶', 'æ‰¾', 'æœç´¢'];
        let query = userMessage;
        stopWords.forEach(word => {
            query = query.replace(new RegExp(word, 'g'), '');
        });
        query = query.trim();
        if (!query || query.length < 2) return null;

        const matches: Array<{ name: string, preview: string }> = [];
        filePreviews.forEach((preview, name) => {
            if (name.includes(query) || preview.includes(query)) {
                matches.push({ name, preview });
            }
        });

        if (matches.length === 0) return null;

        const resultList = matches.slice(0, 5).map((m, i) =>
            `${i + 1}. ${m.name}${m.preview ? `\n   æ‘˜è¦ï¼š${m.preview}` : ''}`
        ).join('\n');

        return `ã€æœç´¢ç»“æœã€‘"${query}"åŒ¹é…åˆ° ${matches.length} ä¸ªæ–‡ä»¶ï¼š\n${resultList}`;
    }, [filePreviews]);

    /**
     * å‘é€æ¶ˆæ¯
     */
    const sendMessage = useCallback(async (content: string) => {
        if (!content.trim() || isGenerating) return;
        if (status !== 'ready') {
            console.warn('âš ï¸ Ollama æœåŠ¡æœªå°±ç»ª');
            return;
        }

        const userMessage: ChatMessage = {
            id: generateId(),
            role: 'user',
            content: content.trim(),
            timestamp: Date.now()
        };

        const assistantMessage: ChatMessage = {
            id: generateId(),
            role: 'assistant',
            content: '',
            timestamp: Date.now(),
            isStreaming: true
        };

        const newMessages = [...messages, userMessage, assistantMessage];
        setMessages(newMessages);
        setIsGenerating(true);

        // æ„å»º LLM æ¶ˆæ¯
        const llmMessages: LLMMessage[] = [];
        const contextInfo = buildContextInfo();
        const searchResult = searchFiles(content.trim());

        let systemContent = getSystemPrompt();
        if (contextInfo) systemContent += '\n\n' + contextInfo;
        if (searchResult) systemContent += '\n\n' + searchResult;
        llmMessages.push({ role: 'system', content: systemContent });

        messages.forEach(m => {
            llmMessages.push({ role: m.role, content: m.content });
        });
        llmMessages.push({ role: 'user', content: content.trim() });

        const onToken = (token: string) => {
            setMessages(prev => {
                const updated = [...prev];
                const lastMsg = updated[updated.length - 1];
                if (lastMsg && lastMsg.role === 'assistant') {
                    lastMsg.content += token;
                }
                return updated;
            });
        };

        const onComplete = async () => {
            setMessages(prev => {
                const updated = [...prev];
                const lastMsg = updated[updated.length - 1];
                if (lastMsg) lastMsg.isStreaming = false;
                return updated;
            });
            setIsGenerating(false);

            // ä¿å­˜èŠå¤©è®°å½•
            if (activeChatPath) {
                const finalMessages = [...newMessages];
                finalMessages[finalMessages.length - 1].isStreaming = false;

                if (activeChatPath.startsWith('__')) {
                    sessionChatCache.current.set(activeChatPath, finalMessages);
                } else if (window.chat) {
                    try {
                        await window.chat.save(activeChatPath, finalMessages);
                    } catch (error) {
                        console.error('ä¿å­˜èŠå¤©è®°å½•å¤±è´¥:', error);
                    }
                }
            }
        };

        const onError = (error: Error) => {
            console.error('âŒ ç”Ÿæˆé”™è¯¯:', error);
            setMessages(prev => {
                const updated = [...prev];
                const lastMsg = updated[updated.length - 1];
                if (lastMsg && lastMsg.role === 'assistant') {
                    lastMsg.content = `âŒ ç”Ÿæˆå‡ºé”™: ${error.message}`;
                    lastMsg.isStreaming = false;
                }
                return updated;
            });
            setIsGenerating(false);
        };

        try {
            if (ollamaServiceRef.current) {
                await ollamaServiceRef.current.streamChat(llmMessages, onToken, onComplete, onError);
            } else {
                throw new Error('Ollama æœåŠ¡æœªåˆå§‹åŒ–');
            }
        } catch (error) {
            onError(error instanceof Error ? error : new Error('æœªçŸ¥é”™è¯¯'));
        }
    }, [messages, isGenerating, status, activeChatPath, buildContextInfo, getSystemPrompt, searchFiles]);

    /**
     * åŠ è½½èŠå¤©å†å²
     */
    const loadChatHistory = useCallback(async (chatPath: string): Promise<ChatMessage[]> => {
        setActiveChatPath(chatPath);

        if (chatPath.startsWith('__')) {
            const cached = sessionChatCache.current.get(chatPath) || [];
            setMessages(cached);
            return cached;
        }

        if (!window.chat) return [];
        try {
            const history = await window.chat.load(chatPath) as ChatMessage[];
            setMessages(history || []);
            return history || [];
        } catch (error) {
            console.error('åŠ è½½èŠå¤©è®°å½•å¤±è´¥:', error);
            setMessages([]);
            return [];
        }
    }, []);

    /**
     * ä¸­æ­¢ç”Ÿæˆ
     */
    const abortGeneration = useCallback(() => {
        if (ollamaServiceRef.current) {
            ollamaServiceRef.current.abort();
        }
        setIsGenerating(false);
    }, []);

    /**
     * æ¸…ç©ºæ¶ˆæ¯
     */
    const clearMessages = useCallback(() => {
        setMessages([]);
    }, []);

    /**
     * é‡æ–°æ£€æµ‹
     */
    const retryDetection = useCallback(() => {
        detectAndInitialize();
    }, [detectAndInitialize]);

    /**
     * åˆ‡æ¢ Ollama æ¨¡å‹
     */
    const handleSetSelectedOllamaModel = useCallback((model: string) => {
        setSelectedOllamaModel(model);
        setModelName(model);
        // ä¿å­˜åˆ° localStorage
        localStorage.setItem('zen-selected-ollama-model', model);
        if (ollamaServiceRef.current) {
            ollamaServiceRef.current.setModel(model);
        }
    }, []);

    /**
     * å¸è½½æ¨¡å‹
     */
    const unloadModel = useCallback(() => {
        console.log('ğŸ“¤ å¸è½½ Ollama æ¨¡å‹...');
        ollamaServiceRef.current = null;
        setStatus('detecting');
        setModelName('');
    }, []);

    /**
     * æ³¨å…¥æ¶ˆæ¯
     */
    const injectMessage = useCallback((role: 'system' | 'user' | 'assistant', content: string) => {
        const newMessage: ChatMessage = {
            id: generateId(),
            role,
            content,
            timestamp: Date.now()
        };
        setMessages(prev => [...prev, newMessage]);
    }, []);

    // å¯åŠ¨æ—¶æ£€æµ‹
    useEffect(() => {
        detectAndInitialize();
    }, [detectAndInitialize]);

    return {
        status,
        modelName,
        loadProgress,
        errorMessage,
        ollamaModels,
        selectedOllamaModel,
        setSelectedOllamaModel: handleSetSelectedOllamaModel,
        messages,
        isGenerating,
        contextType,
        activeFilePath,
        activeFileName,
        activeFileContent,
        activeFolderName,
        activeFolderFiles,
        setActiveFileContext,
        setActiveFolderContext,
        sendMessage,
        abortGeneration,
        clearMessages,
        injectMessage,
        setMessages,
        retryDetection,
        loadChatHistory,
        unloadModel,
        refreshModels,
        pullModel,
        deleteModel,
        cancelPull,
        downloadProgressMap
    };
}

export default useLLM;
