/**
 * Engine Store - Áä∂ÊÄÅÁÆ°ÁêÜ
 * ÁÆ°ÁêÜ AI ÂºïÊìéÁöÑÁä∂ÊÄÅÔºöWebLLM / Ollama / Cloud API
 */

import { useState, useEffect, useCallback, useRef } from 'react';
import { OllamaModel } from '../services/types';
import { WebLLMEngine } from '../engines/WebLLMEngine';
import { OpenAIEngine } from '../engines/OpenAIEngine';
import { ALL_WEBLLM_MODELS_INFO, DEFAULT_WEBLLM_MODEL } from '../engines/webllmModels';

// ÂºïÊìéÁ±ªÂûã
export type EngineType = 'webllm' | 'ollama' | 'openai';

// Ollama ÈÖçÁΩÆ
interface OllamaConfig {
    host: string;
    port: number;
}

// Cloud API ÈÖçÁΩÆ
interface CloudConfig {
    apiKey: string;
    baseUrl: string;
    modelName: string;
    provider: 'openai' | 'deepseek' | 'custom';
}

// WebLLM ËøõÂ∫¶
interface WebLLMProgress {
    progress: number;
    text: string;
}

// Ë∞ÉËØïÁî®ÔºöÊúÄÂêéÁîüÊàê‰ø°ÊÅØ
interface LastGenerationInfo {
    timestamp: number;
    model: string;
    systemPrompt: string;
    userContext: string;
    contextLength: number;
}

// ÂØºÂá∫ËøîÂõûÁ±ªÂûã
export interface UseEngineStoreReturn {
    // ÂºïÊìéÂàáÊç¢
    currentEngine: EngineType;
    setEngine: (engine: EngineType) => void;

    // WebLLM Áä∂ÊÄÅ
    webllmReady: boolean;
    webllmLoading: boolean;
    webllmProgress: WebLLMProgress | null;
    webllmFirstTimeSetup: boolean;
    webllmCachedModels: string[];
    initWebLLM: (modelId?: string) => Promise<void>;
    completeWebLLMSetup: () => void;
    resetWebLLMSetup: () => void;
    deleteWebLLMModel: (modelId: string) => Promise<void>;

    // Ê®°ÂûãÈÄâÊã©
    selectedModel: string;
    selectModel: (model: string) => void;

    // Ollama Áä∂ÊÄÅ
    ollamaAvailable: boolean;
    ollamaModels: OllamaModel[];
    ollamaConfig: OllamaConfig;
    updateOllamaConfig: (config: Partial<OllamaConfig>) => void;
    refreshOllamaStatus: () => Promise<void>;

    // Cloud API Áä∂ÊÄÅ
    cloudConfig: CloudConfig;
    cloudApiStatus: 'idle' | 'loading' | 'success' | 'error';
    updateCloudConfig: (config: Partial<CloudConfig>) => void;
    testCloudApi: () => Promise<void>;

    // ÈÄöÁî®
    error: string | null;
    reportError: (message: string) => void;
    getEngine: () => WebLLMEngine | OpenAIEngine | null;

    // Ë∞ÉËØï
    lastGenerationInfo: LastGenerationInfo | null;
    setLastGenerationInfo: (info: LastGenerationInfo) => void;
}

// Â≠òÂÇ®ÈîÆ
const STORAGE_KEYS = {
    CURRENT_ENGINE: 'zen-current-engine',
    SELECTED_MODEL: 'zen-selected-model',
    WEBLLM_MODEL: 'zen-selected-webllm-model',
    OLLAMA_MODEL: 'zen-selected-ollama-model',
    OLLAMA_HOST: 'zen-ollama-host',
    OLLAMA_PORT: 'zen-ollama-port',
    CLOUD_API_KEY: 'zen-cloud-api-key',
    CLOUD_BASE_URL: 'zen-cloud-base-url',
    CLOUD_MODEL_NAME: 'zen-cloud-model-name',
    CLOUD_PROVIDER: 'zen-cloud-provider',
    WEBLLM_FIRST_TIME: 'zen-webllm-first-time-setup',
};

export function useEngineStore(): UseEngineStoreReturn {
    // ÂºïÊìéÁ±ªÂûã
    const [currentEngine, setCurrentEngine] = useState<EngineType>(() => {
        const saved = localStorage.getItem(STORAGE_KEYS.CURRENT_ENGINE);
        return (saved as EngineType) || 'ollama';
    });

    // WebLLM Áä∂ÊÄÅ
    const [webllmReady, setWebllmReady] = useState(false);
    const [webllmLoading, setWebllmLoading] = useState(false);
    const [webllmProgress, setWebllmProgress] = useState<WebLLMProgress | null>(null);
    const [webllmFirstTimeSetup, setWebllmFirstTimeSetup] = useState(() => {
        return localStorage.getItem(STORAGE_KEYS.WEBLLM_FIRST_TIME) !== 'false';
    });
    const [webllmCachedModels, setWebllmCachedModels] = useState<string[]>([]);
    const webllmEngineRef = useRef<WebLLMEngine | null>(null);

    // Ê®°ÂûãÈÄâÊã©
    const [selectedModel, setSelectedModel] = useState(() => {
        const engine = localStorage.getItem(STORAGE_KEYS.CURRENT_ENGINE) || 'ollama';
        if (engine === 'webllm') {
            return localStorage.getItem(STORAGE_KEYS.WEBLLM_MODEL) || DEFAULT_WEBLLM_MODEL;
        } else if (engine === 'ollama') {
            return localStorage.getItem(STORAGE_KEYS.OLLAMA_MODEL) || '';
        } else {
            return localStorage.getItem(STORAGE_KEYS.CLOUD_MODEL_NAME) || 'gpt-4o-mini';
        }
    });

    // Ollama Áä∂ÊÄÅ
    const [ollamaAvailable, setOllamaAvailable] = useState(false);
    const [ollamaModels, setOllamaModels] = useState<OllamaModel[]>([]);
    const [ollamaConfig, setOllamaConfig] = useState<OllamaConfig>(() => ({
        host: localStorage.getItem(STORAGE_KEYS.OLLAMA_HOST) || '127.0.0.1',
        port: parseInt(localStorage.getItem(STORAGE_KEYS.OLLAMA_PORT) || '11434'),
    }));

    // Cloud API Áä∂ÊÄÅ
    const [cloudConfig, setCloudConfig] = useState<CloudConfig>(() => ({
        apiKey: localStorage.getItem(STORAGE_KEYS.CLOUD_API_KEY) || '',
        baseUrl: localStorage.getItem(STORAGE_KEYS.CLOUD_BASE_URL) || 'https://api.openai.com/v1',
        modelName: localStorage.getItem(STORAGE_KEYS.CLOUD_MODEL_NAME) || 'gpt-4o-mini',
        provider: (localStorage.getItem(STORAGE_KEYS.CLOUD_PROVIDER) as CloudConfig['provider']) || 'openai',
    }));
    const [cloudApiStatus, setCloudApiStatus] = useState<'idle' | 'loading' | 'success' | 'error'>('idle');
    const cloudEngineRef = useRef<OpenAIEngine | null>(null);

    // ÈîôËØØÁä∂ÊÄÅ
    const [error, setError] = useState<string | null>(null);

    // Ë∞ÉËØïÁä∂ÊÄÅ
    const [lastGenerationInfo, setLastGenerationInfo] = useState<LastGenerationInfo | null>(null);

    // Ê£ÄÊµã WebLLM ÁºìÂ≠ò
    useEffect(() => {
        const checkCache = async () => {
            try {
                if ('caches' in window) {
                    const cacheNames = await caches.keys();
                    const webllmCaches = cacheNames.filter(name =>
                        name.includes('webllm') || name.includes('mlc')
                    );

                    // Ê£ÄÊü•ÊØè‰∏™Ê®°ÂûãÊòØÂê¶Â∑≤ÁºìÂ≠ò
                    const cached: string[] = [];
                    for (const modelInfo of ALL_WEBLLM_MODELS_INFO) {
                        // ÁÆÄÂçïÊ£ÄÊü•ÔºöÂ¶ÇÊûúÊúâ‰ªª‰ΩïÁºìÂ≠òÔºåÂ∞±ËÆ§‰∏∫Ê®°ÂûãÂèØËÉΩÂ∑≤ÁºìÂ≠ò
                        // Êõ¥Á≤æÁ°ÆÁöÑÊ£ÄÊü•ÈúÄË¶ÅÂàÜÊûêÁºìÂ≠òÂÜÖÂÆπ
                        if (webllmCaches.length > 0) {
                            const modelCache = await caches.open(modelInfo.model_id);
                            const keys = await modelCache.keys();
                            if (keys.length > 0) {
                                cached.push(modelInfo.model_id);
                            }
                        }
                    }
                    setWebllmCachedModels(cached);
                }
            } catch (e) {
                console.log('Ê£ÄÊü• WebLLM ÁºìÂ≠òÂ§±Ë¥•:', e);
            }
        };
        checkCache();
    }, []);

    // ËÆæÁΩÆÂºïÊìé
    const setEngine = useCallback((engine: EngineType) => {
        setCurrentEngine(engine);
        localStorage.setItem(STORAGE_KEYS.CURRENT_ENGINE, engine);
        setError(null);

        // ÂàáÊç¢ÂºïÊìéÊó∂Êõ¥Êñ∞ÈÄâ‰∏≠ÁöÑÊ®°Âûã
        if (engine === 'webllm') {
            const saved = localStorage.getItem(STORAGE_KEYS.WEBLLM_MODEL);
            setSelectedModel(saved || DEFAULT_WEBLLM_MODEL);
        } else if (engine === 'ollama') {
            const saved = localStorage.getItem(STORAGE_KEYS.OLLAMA_MODEL);
            setSelectedModel(saved || ollamaModels[0]?.name || '');
        } else {
            setSelectedModel(cloudConfig.modelName);
        }
    }, [ollamaModels, cloudConfig.modelName]);

    // ÂàùÂßãÂåñ WebLLM
    const initWebLLM = useCallback(async (modelId?: string) => {
        const targetModel = modelId || selectedModel || DEFAULT_WEBLLM_MODEL;

        console.log('üöÄ ÂàùÂßãÂåñ WebLLM:', targetModel);
        setWebllmLoading(true);
        setWebllmReady(false);
        setError(null);
        setWebllmProgress({ progress: 0, text: 'Ê≠£Âú®ÂàùÂßãÂåñ...' });

        try {
            // ÂàõÂª∫Êñ∞ÁöÑÂºïÊìéÂÆû‰æã
            const engine = new WebLLMEngine(targetModel);

            await engine.initialize((progress) => {
                setWebllmProgress({
                    progress: progress.progress || 0,
                    text: progress.text || 'Âä†ËΩΩ‰∏≠...'
                });
            });

            webllmEngineRef.current = engine;
            setWebllmReady(true);
            setSelectedModel(targetModel);
            localStorage.setItem(STORAGE_KEYS.WEBLLM_MODEL, targetModel);

            // Êõ¥Êñ∞ÁºìÂ≠òÂàóË°®
            if (!webllmCachedModels.includes(targetModel)) {
                setWebllmCachedModels(prev => [...prev, targetModel]);
            }

            console.log('‚úÖ WebLLM ÂàùÂßãÂåñÊàêÂäü');
        } catch (e) {
            console.error('‚ùå WebLLM ÂàùÂßãÂåñÂ§±Ë¥•:', e);
            setError(e instanceof Error ? e.message : 'WebLLM ÂàùÂßãÂåñÂ§±Ë¥•');
            setWebllmReady(false);
        } finally {
            setWebllmLoading(false);
            setWebllmProgress(null);
        }
    }, [selectedModel, webllmCachedModels]);

    // ÂÆåÊàêÈ¶ñÊ¨°ËÆæÁΩÆ
    const completeWebLLMSetup = useCallback(() => {
        setWebllmFirstTimeSetup(false);
        localStorage.setItem(STORAGE_KEYS.WEBLLM_FIRST_TIME, 'false');
    }, []);

    // ÈáçÁΩÆ WebLLM ËÆæÁΩÆ
    const resetWebLLMSetup = useCallback(() => {
        setWebllmLoading(false);
        setWebllmProgress(null);
        webllmEngineRef.current = null;
    }, []);

    // Âà†Èô§ WebLLM Ê®°ÂûãÁºìÂ≠ò
    const deleteWebLLMModel = useCallback(async (modelId: string) => {
        try {
            // Ê∏ÖÈô§ÁºìÂ≠ò
            if ('caches' in window) {
                const cacheNames = await caches.keys();
                for (const cacheName of cacheNames) {
                    if (cacheName.includes(modelId) || cacheName.includes('webllm') || cacheName.includes('mlc')) {
                        await caches.delete(cacheName);
                    }
                }
            }

            // Êõ¥Êñ∞Áä∂ÊÄÅ
            setWebllmCachedModels(prev => prev.filter(m => m !== modelId));

            // Â¶ÇÊûúÂà†Èô§ÁöÑÊòØÂΩìÂâçÊ®°ÂûãÔºåÈáçÁΩÆÁä∂ÊÄÅ
            if (selectedModel === modelId) {
                setWebllmReady(false);
                webllmEngineRef.current = null;
            }

            console.log('‚úÖ Â∑≤Âà†Èô§Ê®°ÂûãÁºìÂ≠ò:', modelId);
        } catch (e) {
            console.error('‚ùå Âà†Èô§Ê®°ÂûãÁºìÂ≠òÂ§±Ë¥•:', e);
        }
    }, [selectedModel]);

    // ÈÄâÊã©Ê®°Âûã
    const selectModel = useCallback((model: string) => {
        setSelectedModel(model);

        if (currentEngine === 'webllm') {
            localStorage.setItem(STORAGE_KEYS.WEBLLM_MODEL, model);
        } else if (currentEngine === 'ollama') {
            localStorage.setItem(STORAGE_KEYS.OLLAMA_MODEL, model);
        } else {
            localStorage.setItem(STORAGE_KEYS.CLOUD_MODEL_NAME, model);
        }
    }, [currentEngine]);

    // Êõ¥Êñ∞ Ollama ÈÖçÁΩÆ
    const updateOllamaConfig = useCallback((config: Partial<OllamaConfig>) => {
        setOllamaConfig(prev => {
            const updated = { ...prev, ...config };
            if (config.host !== undefined) {
                localStorage.setItem(STORAGE_KEYS.OLLAMA_HOST, config.host);
            }
            if (config.port !== undefined) {
                localStorage.setItem(STORAGE_KEYS.OLLAMA_PORT, String(config.port));
            }
            return updated;
        });
    }, []);

    // Âà∑Êñ∞ Ollama Áä∂ÊÄÅ
    const refreshOllamaStatus = useCallback(async () => {
        try {
            const response = await fetch(`http://${ollamaConfig.host}:${ollamaConfig.port}/api/tags`);
            if (response.ok) {
                const data = await response.json();
                setOllamaAvailable(true);
                if (Array.isArray(data.models)) {
                    const models: OllamaModel[] = data.models.map((m: any) => ({
                        name: m.name,
                        size: m.size || 0,
                        digest: m.digest || '',
                        modified_at: m.modified_at || '',
                        formattedSize: formatSize(m.size || 0),
                    }));
                    setOllamaModels(models);

                    // Â¶ÇÊûúÊ≤°ÊúâÈÄâ‰∏≠Ê®°ÂûãÔºåÈÄâÊã©Á¨¨‰∏Ä‰∏™
                    if (!selectedModel && models.length > 0) {
                        selectModel(models[0].name);
                    }
                }
            } else {
                setOllamaAvailable(false);
            }
        } catch (e) {
            console.log('Ollama ËøûÊé•Â§±Ë¥•:', e);
            setOllamaAvailable(false);
        }
    }, [ollamaConfig.host, ollamaConfig.port, selectedModel, selectModel]);

    // ÂàùÂßãÂåñÊó∂Ê£ÄÊµã Ollama
    useEffect(() => {
        if (currentEngine === 'ollama') {
            refreshOllamaStatus();
        }
    }, [currentEngine, refreshOllamaStatus]);

    // Êõ¥Êñ∞ Cloud ÈÖçÁΩÆ
    const updateCloudConfig = useCallback((config: Partial<CloudConfig>) => {
        setCloudConfig(prev => {
            const updated = { ...prev, ...config };
            if (config.apiKey !== undefined) {
                localStorage.setItem(STORAGE_KEYS.CLOUD_API_KEY, config.apiKey);
            }
            if (config.baseUrl !== undefined) {
                localStorage.setItem(STORAGE_KEYS.CLOUD_BASE_URL, config.baseUrl);
            }
            if (config.modelName !== undefined) {
                localStorage.setItem(STORAGE_KEYS.CLOUD_MODEL_NAME, config.modelName);
                setSelectedModel(config.modelName);
            }
            if (config.provider !== undefined) {
                localStorage.setItem(STORAGE_KEYS.CLOUD_PROVIDER, config.provider);
            }
            return updated;
        });
    }, []);

    // ÊµãËØï Cloud API
    const testCloudApi = useCallback(async () => {
        if (!cloudConfig.apiKey) {
            setCloudApiStatus('error');
            setError('ËØ∑ÂÖàÈÖçÁΩÆ API Key');
            return;
        }

        setCloudApiStatus('loading');
        setError(null);

        try {
            const engine = new OpenAIEngine({
                apiKey: cloudConfig.apiKey,
                baseUrl: cloudConfig.baseUrl,
                modelName: cloudConfig.modelName
            });

            const success = await engine.testConnection();
            if (success) {
                cloudEngineRef.current = engine;
                setCloudApiStatus('success');
                console.log('‚úÖ Cloud API ÊµãËØïÊàêÂäü');
            } else {
                throw new Error('ËøûÊé•ÊµãËØïÂ§±Ë¥•');
            }
        } catch (e) {
            console.error('‚ùå Cloud API ÊµãËØïÂ§±Ë¥•:', e);
            setCloudApiStatus('error');
            setError(e instanceof Error ? e.message : 'API ËøûÊé•Â§±Ë¥•');
        }
    }, [cloudConfig]);

    // Êä•ÂëäÈîôËØØ
    const reportError = useCallback((message: string) => {
        setError(message);
    }, []);

    // Ëé∑ÂèñÂΩìÂâçÂºïÊìéÂÆû‰æã
    const getEngine = useCallback(() => {
        if (currentEngine === 'webllm') {
            return webllmEngineRef.current;
        } else if (currentEngine === 'openai') {
            return cloudEngineRef.current;
        }
        return null;
    }, [currentEngine]);

    return {
        currentEngine,
        setEngine,

        webllmReady,
        webllmLoading,
        webllmProgress,
        webllmFirstTimeSetup,
        webllmCachedModels,
        initWebLLM,
        completeWebLLMSetup,
        resetWebLLMSetup,
        deleteWebLLMModel,

        selectedModel,
        selectModel,

        ollamaAvailable,
        ollamaModels,
        ollamaConfig,
        updateOllamaConfig,
        refreshOllamaStatus,

        cloudConfig,
        cloudApiStatus,
        updateCloudConfig,
        testCloudApi,

        error,
        reportError,
        getEngine,

        lastGenerationInfo,
        setLastGenerationInfo,
    };
}

// ËæÖÂä©ÂáΩÊï∞ÔºöÊ†ºÂºèÂåñÊñá‰ª∂Â§ßÂ∞è
function formatSize(bytes: number): string {
    if (bytes === 0) return '0 B';
    const k = 1024;
    const sizes = ['B', 'KB', 'MB', 'GB'];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return `${(bytes / Math.pow(k, i)).toFixed(1)} ${sizes[i]}`;
}

export default useEngineStore;
