/**
 * Engine Store - ä¸‰å¼•æ“çŠ¶æ€ç®¡ç†
 * ç®¡ç† WebLLM, Ollama, Cloud API ä¸‰ç§å¼•æ“çš„çŠ¶æ€
 */

import { useState, useEffect, useCallback, useRef } from 'react';
import { OpenAIEngine, CloudConfig, DEFAULT_CLOUD_CONFIG } from '../engines/OpenAIEngine';
import { DEFAULT_WEBLLM_MODEL } from '../engines/webllmModels';
import { OllamaModel } from '../services/types';

export type EngineType = 'webllm' | 'ollama' | 'openai';

export interface OllamaConfig {
    host: string;
    port: number;
}

export interface EngineState {
    currentEngine: EngineType;
    selectedModel: string;

    // WebLLM çŠ¶æ€
    webllmReady: boolean;
    webllmLoading: boolean;
    webllmProgress: { progress: number; text: string } | null;
    webllmCachedModels: string[];

    // Ollama çŠ¶æ€
    ollamaAvailable: boolean;
    ollamaConfig: OllamaConfig;
    ollamaModels: OllamaModel[];

    // Cloud API çŠ¶æ€
    cloudConfig: CloudConfig;
    cloudApiStatus: 'untested' | 'success' | 'error';

    // é€šç”¨
    isLoading: boolean;
    error: string | null;
}

export interface UseEngineStoreReturn extends EngineState {
    setEngine: (engine: EngineType) => void;
    selectModel: (modelId: string) => void;

    // WebLLM
    initWebLLM: (modelId?: string) => Promise<void>;
    refreshWebLLMCache: () => Promise<void>;
    deleteWebLLMModel: (modelId: string) => Promise<void>;
    clearAllWebLLMCache: () => Promise<void>;

    // Ollama
    updateOllamaConfig: (config: Partial<OllamaConfig>) => void;
    refreshOllamaStatus: () => Promise<void>;

    // Cloud API
    updateCloudConfig: (config: Partial<CloudConfig>) => void;
    testCloudApi: () => Promise<boolean>;

    // å¼•æ“è®¿é—®
    getEngine: () => any;

    // é”™è¯¯æŠ¥å‘Š
    reportError: (error: string) => void;
}

const STORAGE_KEYS = {
    ENGINE: 'zen-ai-engine',
    MODEL: 'zen-selected-model',
    WEBLLM_MODEL: 'zen-selected-webllm-model',
    OLLAMA_MODEL: 'zen-selected-ollama-model',
    OLLAMA: 'zen-ollama-config',
    CLOUD: 'zen-cloud-config'
};

export function useEngineStore(): UseEngineStoreReturn {
    // ä» localStorage æ¢å¤é…ç½®ï¼ˆé»˜è®¤ä½¿ç”¨ Ollamaï¼ŒWebLLM æœ‰å·²çŸ¥é—®é¢˜ï¼‰
    const savedEngine = (localStorage.getItem(STORAGE_KEYS.ENGINE) as EngineType) || 'ollama';
    const savedModel = localStorage.getItem(STORAGE_KEYS.MODEL) || DEFAULT_WEBLLM_MODEL;
    const savedOllamaConfig: OllamaConfig = JSON.parse(
        localStorage.getItem(STORAGE_KEYS.OLLAMA) || '{"host":"127.0.0.1","port":11434}'
    );
    const savedCloudConfig: CloudConfig = JSON.parse(
        localStorage.getItem(STORAGE_KEYS.CLOUD) || JSON.stringify(DEFAULT_CLOUD_CONFIG)
    );

    const [state, setState] = useState<EngineState>({
        currentEngine: savedEngine,
        selectedModel: savedModel,
        webllmReady: false,
        webllmLoading: false,
        webllmProgress: null,
        webllmCachedModels: [],
        ollamaAvailable: false,
        ollamaConfig: savedOllamaConfig,
        ollamaModels: [],
        cloudConfig: savedCloudConfig,
        cloudApiStatus: 'untested',
        isLoading: true,
        error: null
    });

    // å¼•æ“å®ä¾‹å¼•ç”¨
    const openaiEngineRef = useRef<OpenAIEngine | null>(null);
    const webllmEngineRef = useRef<any>(null);
    // åˆå§‹åŒ–é”ï¼ˆä½¿ç”¨ ref è€Œé stateï¼Œç¡®ä¿åŒæ­¥æ£€æŸ¥ï¼Œé˜²æ­¢ React Strict Mode ä¸‹çš„é‡å¤åˆå§‹åŒ–ï¼‰
    const webllmInitLockRef = useRef<boolean>(false);

    // è®¾ç½®å¼•æ“
    const setEngine = useCallback((engine: EngineType) => {
        localStorage.setItem(STORAGE_KEYS.ENGINE, engine);

        // åˆ‡æ¢å¼•æ“æ—¶ï¼Œæ¢å¤è¯¥å¼•æ“ä¸Šæ¬¡ä½¿ç”¨çš„æ¨¡å‹
        let modelToRestore = DEFAULT_WEBLLM_MODEL;
        if (engine === 'webllm') {
            modelToRestore = localStorage.getItem(STORAGE_KEYS.WEBLLM_MODEL) || DEFAULT_WEBLLM_MODEL;
        } else if (engine === 'ollama') {
            // å¦‚æœåªæœ‰ nullï¼Œå¯ä»¥ä¿ç•™å½“å‰é€‰ä¸­ï¼ˆä½†é£é™©æ˜¯å½“å‰é€‰ä¸­å¯èƒ½æ˜¯ webllm çš„ï¼‰ï¼Œæˆ–è€…ç”¨ç¬¬ä¸€ä¸ª found model
            modelToRestore = localStorage.getItem(STORAGE_KEYS.OLLAMA_MODEL) || '';
        } else if (engine === 'openai') {
            modelToRestore = state.cloudConfig.modelName;
        }

        setState(prev => ({
            ...prev,
            currentEngine: engine,
            selectedModel: modelToRestore,
            error: null
        }));
    }, [state.cloudConfig.modelName]);

    // é€‰æ‹©æ¨¡å‹
    const selectModel = useCallback((modelId: string) => {
        localStorage.setItem(STORAGE_KEYS.MODEL, modelId);

        // åˆ†åˆ«å­˜å‚¨å¼•æ“çš„æ¨¡å‹é€‰æ‹©
        if (state.currentEngine === 'webllm') {
            localStorage.setItem(STORAGE_KEYS.WEBLLM_MODEL, modelId);
        } else if (state.currentEngine === 'ollama') {
            localStorage.setItem(STORAGE_KEYS.OLLAMA_MODEL, modelId);
        }

        setState(prev => ({ ...prev, selectedModel: modelId }));
    }, [state.currentEngine]);

    // åˆå§‹åŒ– WebLLM
    const initWebLLM = useCallback(async (modelId?: string) => {
        // ä½¿ç”¨ ref ä½œä¸ºåˆå§‹åŒ–é”ï¼ˆåŒæ­¥æ£€æŸ¥ï¼‰ï¼Œé˜²æ­¢ React Strict Mode ä¸‹çš„å¹¶å‘åˆå§‹åŒ–
        if (webllmInitLockRef.current) {
            console.log('âš ï¸ WebLLM æ­£åœ¨åˆå§‹åŒ–ä¸­ï¼ˆé”å®šï¼‰ï¼Œè·³è¿‡...');
            return;
        }

        // ç«‹å³è®¾ç½®é”ï¼ˆåŒæ­¥æ“ä½œï¼‰
        webllmInitLockRef.current = true;
        console.log('ğŸ”’ WebLLM åˆå§‹åŒ–é”å·²è®¾ç½®');

        const targetModel = modelId || state.selectedModel;

        // å–æ¶ˆä¹‹å‰çš„ä¸‹è½½
        if (webllmEngineRef.current?.abort) {
            webllmEngineRef.current.abort();
        }

        setState(prev => ({
            ...prev,
            webllmLoading: true,
            webllmReady: false,
            webllmProgress: { progress: 0, text: 'åˆå§‹åŒ–ä¸­...' },
            selectedModel: targetModel,
            error: null // æ¸…é™¤ä¹‹å‰çš„é”™è¯¯
        }));

        try {
            // åŠ¨æ€å¯¼å…¥ WebLLM
            const { CreateMLCEngine } = await import('@mlc-ai/web-llm');

            // ç¡®ä¿ä¹‹å‰çš„å¼•æ“å·²å¸è½½
            if (webllmEngineRef.current && webllmEngineRef.current.unload) {
                await webllmEngineRef.current.unload();
            }

            const engine = await CreateMLCEngine(targetModel, {
                initProgressCallback: (progress) => {
                    setState(prev => ({
                        ...prev,
                        webllmProgress: {
                            progress: progress.progress,
                            text: progress.text
                        }
                    }));
                }
            });

            webllmEngineRef.current = engine;
            localStorage.setItem(STORAGE_KEYS.MODEL, targetModel);

            // é¢„çƒ­å¼•æ“ï¼Œç¡®ä¿ Tokenizer çš„ WASM ç»‘å®šå®Œå…¨å°±ç»ª
            // å¢åŠ é‡è¯•æœºåˆ¶ï¼Œè§£å†³"ç¬¬ä¸€å¥è¯æ€»æ˜¯å¤±è´¥"çš„é—®é¢˜
            const MAX_WARMUP_RETRIES = 3;
            let warmupSuccess = false;

            for (let attempt = 1; attempt <= MAX_WARMUP_RETRIES; attempt++) {
                // æ¯æ¬¡é‡è¯•å‰ç­‰å¾…æ›´é•¿æ—¶é—´ï¼Œç»™ WASM ç»‘å®šæ›´å¤šåˆå§‹åŒ–æ—¶é—´
                const waitTime = attempt * 1000; // 1ç§’, 2ç§’, 3ç§’
                console.log(`ğŸ”¥ é¢„çƒ­ WebLLM å¼•æ“ (å°è¯• ${attempt}/${MAX_WARMUP_RETRIES})ï¼Œç­‰å¾… ${waitTime}ms...`);
                await new Promise(resolve => setTimeout(resolve, waitTime));

                try {
                    await engine.chat.completions.create({
                        messages: [{ role: 'user', content: 'hi' }],
                        max_tokens: 1
                    });
                    console.log('âœ… WebLLM å¼•æ“é¢„çƒ­æˆåŠŸ');
                    // é¢„çƒ­åé‡ç½®èŠå¤©çŠ¶æ€ï¼Œæ¸…é™¤ KV Cacheï¼Œé¿å…å½±å“åç»­å¯¹è¯
                    await engine.resetChat();
                    warmupSuccess = true;
                    break; // æˆåŠŸåˆ™é€€å‡ºé‡è¯•å¾ªç¯
                } catch (warmupError) {
                    console.warn(`âš ï¸ WebLLM é¢„çƒ­å¤±è´¥ (å°è¯• ${attempt}/${MAX_WARMUP_RETRIES}):`, warmupError);
                    if (attempt === MAX_WARMUP_RETRIES) {
                        console.warn('âš ï¸ æ‰€æœ‰é¢„çƒ­å°è¯•å‡å¤±è´¥ï¼Œä½†å¼•æ“ä»å¯èƒ½å¯ç”¨');
                    }
                }
            }

            console.log(`ğŸ WebLLM åˆå§‹åŒ–å®Œæˆï¼Œé¢„çƒ­çŠ¶æ€: ${warmupSuccess ? 'æˆåŠŸ' : 'å¤±è´¥ä½†ç»§ç»­'}`);

            // é‡Šæ”¾åˆå§‹åŒ–é”
            webllmInitLockRef.current = false;
            console.log('ğŸ”“ WebLLM åˆå§‹åŒ–é”å·²é‡Šæ”¾');

            setState(prev => ({
                ...prev,
                webllmLoading: false,
                webllmReady: true,
                webllmProgress: null,
                selectedModel: targetModel
            }));

            // åˆ·æ–°ç¼“å­˜åˆ—è¡¨ä»¥ä¾¿ UI ç«‹å³æ˜¾ç¤ºå·²ä¸‹è½½çŠ¶æ€
            setTimeout(async () => {
                if ('caches' in window) {
                    const cacheNames = await caches.keys();
                    const webllmCaches = cacheNames.filter(name =>
                        name.includes('webllm') || name.includes('mlc')
                    );
                    setState(prev => ({ ...prev, webllmCachedModels: webllmCaches }));
                }
            }, 100);
        } catch (error) {
            console.error('WebLLM åˆå§‹åŒ–å¤±è´¥:', error);
            // é‡Šæ”¾åˆå§‹åŒ–é”
            webllmInitLockRef.current = false;
            console.log('ğŸ”“ WebLLM åˆå§‹åŒ–é”å·²é‡Šæ”¾ï¼ˆå¤±è´¥ï¼‰');

            setState(prev => ({
                ...prev,
                webllmLoading: false,
                webllmReady: false,
                webllmProgress: null,
                error: error instanceof Error ? error.message : 'åˆå§‹åŒ–å¤±è´¥'
            }));
        }
    }, [state.selectedModel]);

    // åˆ·æ–° WebLLM ç¼“å­˜åˆ—è¡¨
    const refreshWebLLMCache = useCallback(async () => {
        try {
            if ('caches' in window) {
                const cacheNames = await caches.keys();
                const webllmCaches = cacheNames.filter(name =>
                    name.includes('webllm') || name.includes('mlc')
                );
                setState(prev => ({ ...prev, webllmCachedModels: webllmCaches }));
            }
        } catch (e) {
            console.warn('æ— æ³•è¯»å–ç¼“å­˜:', e);
        }
    }, []);

    // åˆ é™¤ WebLLM æ¨¡å‹ç¼“å­˜
    const deleteWebLLMModel = useCallback(async (modelId: string) => {
        try {
            if ('caches' in window) {
                const cacheNames = await caches.keys();
                for (const name of cacheNames) {
                    if (name.includes(modelId) || name.includes('webllm')) {
                        await caches.delete(name);
                    }
                }
                await refreshWebLLMCache();
            }
        } catch (e) {
            console.error('åˆ é™¤ç¼“å­˜å¤±è´¥:', e);
        }
    }, [refreshWebLLMCache]);

    // æ¸…ç†æ‰€æœ‰ WebLLM ç¼“å­˜
    const clearAllWebLLMCache = useCallback(async () => {
        try {
            if ('caches' in window) {
                const cacheNames = await caches.keys();
                for (const name of cacheNames) {
                    if (name.includes('webllm') || name.includes('mlc') || name.includes('wasm')) {
                        await caches.delete(name);
                        console.log('ğŸ—‘ï¸ åˆ é™¤ç¼“å­˜:', name);
                    }
                }
                // åŒæ—¶æ¸…ç† IndexedDB
                const databases = await indexedDB.databases();
                for (const db of databases) {
                    if (db.name && (db.name.includes('webllm') || db.name.includes('mlc'))) {
                        indexedDB.deleteDatabase(db.name);
                        console.log('ğŸ—‘ï¸ åˆ é™¤ IndexedDB:', db.name);
                    }
                }
                setState(prev => ({ ...prev, webllmCachedModels: [], webllmReady: false }));
                webllmEngineRef.current = null;
                console.log('âœ… WebLLM ç¼“å­˜å·²æ¸…ç†');
            }
        } catch (e) {
            console.error('æ¸…ç†ç¼“å­˜å¤±è´¥:', e);
        }
    }, []);

    // æ›´æ–° Ollama é…ç½®
    const updateOllamaConfig = useCallback((config: Partial<OllamaConfig>) => {
        setState(prev => {
            const newConfig = { ...prev.ollamaConfig, ...config };
            localStorage.setItem(STORAGE_KEYS.OLLAMA, JSON.stringify(newConfig));
            return { ...prev, ollamaConfig: newConfig };
        });
    }, []);

    // åˆ·æ–° Ollama çŠ¶æ€
    const refreshOllamaStatus = useCallback(async () => {
        const { host, port } = state.ollamaConfig;
        const baseUrl = `http://${host}:${port}`;

        try {
            const response = await fetch(`${baseUrl}/api/tags`, {
                signal: AbortSignal.timeout(5000)
            });

            if (response.ok) {
                const data = await response.json();
                const models = data.models || [];
                setState(prev => ({
                    ...prev,
                    ollamaAvailable: true,
                    ollamaModels: models.map((m: any) => ({
                        name: m.name,
                        size: m.size || 0,
                        digest: m.digest,
                        modified_at: m.modified_at,
                        formattedSize: formatSize(m.size)
                    }))
                }));
            } else {
                setState(prev => ({ ...prev, ollamaAvailable: false, ollamaModels: [] }));
            }
        } catch {
            setState(prev => ({ ...prev, ollamaAvailable: false, ollamaModels: [] }));
        }
    }, [state.ollamaConfig]);

    // Ollama é…ç½®æ”¹å˜æ—¶è‡ªåŠ¨åˆ·æ–°çŠ¶æ€
    useEffect(() => {
        if (state.currentEngine === 'ollama') {
            refreshOllamaStatus();
        }
    }, [state.ollamaConfig.host, state.ollamaConfig.port]);

    // æ›´æ–° Cloud é…ç½®
    const updateCloudConfig = useCallback((config: Partial<CloudConfig>) => {
        setState(prev => {
            const newConfig = { ...prev.cloudConfig, ...config };
            localStorage.setItem(STORAGE_KEYS.CLOUD, JSON.stringify(newConfig));

            // æ›´æ–°å¼•æ“å®ä¾‹
            if (openaiEngineRef.current) {
                openaiEngineRef.current.updateConfig(newConfig);
            }

            return { ...prev, cloudConfig: newConfig, cloudApiStatus: 'untested' };
        });
    }, []);

    // æµ‹è¯• Cloud API
    const testCloudApi = useCallback(async () => {
        if (!openaiEngineRef.current) {
            openaiEngineRef.current = new OpenAIEngine(state.cloudConfig);
        }

        const result = await openaiEngineRef.current.testConnection();
        setState(prev => ({
            ...prev,
            cloudApiStatus: result ? 'success' : 'error'
        }));
        return result;
    }, [state.cloudConfig]);

    // è·å–å½“å‰å¼•æ“å®ä¾‹
    const getEngine = useCallback(() => {
        switch (state.currentEngine) {
            case 'webllm':
                return webllmEngineRef.current;
            case 'openai':
                if (!openaiEngineRef.current) {
                    openaiEngineRef.current = new OpenAIEngine(state.cloudConfig);
                }
                return openaiEngineRef.current;
            default:
                return null;
        }
    }, [state.currentEngine, state.cloudConfig]);

    // æŠ¥å‘Šé”™è¯¯
    const reportError = useCallback((errorMessage: string) => {
        setState(prev => ({
            ...prev,
            webllmReady: false,
            webllmLoading: false,
            error: errorMessage
        }));
    }, []);

    // åˆå§‹åŒ–
    useEffect(() => {
        const init = async () => {
            await refreshOllamaStatus();
            await refreshWebLLMCache();
            setState(prev => ({ ...prev, isLoading: false }));
        };
        init();
    }, []);

    // å¼•æ“åˆ‡æ¢æ—¶è‡ªåŠ¨åˆå§‹åŒ–
    useEffect(() => {
        const initEngine = async () => {
            switch (state.currentEngine) {
                case 'webllm':
                    // WebLLM: å¦‚æœæœªå°±ç»ªä¸”æœ‰é€‰ä¸­æ¨¡å‹ï¼Œåˆ™åˆå§‹åŒ–
                    if (!state.webllmReady && state.selectedModel) {
                        await initWebLLM(state.selectedModel);
                    }
                    break;
                case 'ollama':
                    // Ollama: åˆ·æ–°çŠ¶æ€ï¼ˆå·²åœ¨åˆå§‹åŒ–æ—¶å®Œæˆï¼‰
                    break;
                case 'openai':
                    // Cloud API: åˆ›å»ºå¼•æ“å®ä¾‹
                    if (!openaiEngineRef.current && state.cloudConfig.apiKey) {
                        try {
                            openaiEngineRef.current = new OpenAIEngine(state.cloudConfig);
                            console.log('âœ… Cloud API å¼•æ“å·²åˆ›å»º');
                        } catch (error) {
                            console.error('âŒ Cloud API å¼•æ“åˆ›å»ºå¤±è´¥:', error);
                        }
                    }
                    break;
            }
        };
        initEngine();
    }, [state.currentEngine, state.selectedModel, state.webllmReady, state.cloudConfig.apiKey, initWebLLM]);

    return {
        ...state,
        setEngine,
        selectModel,
        initWebLLM,
        refreshWebLLMCache,
        deleteWebLLMModel,
        clearAllWebLLMCache,
        updateOllamaConfig,
        refreshOllamaStatus,
        updateCloudConfig,
        testCloudApi,
        getEngine,
        reportError
    };
}

// è¾…åŠ©å‡½æ•°
function formatSize(bytes: number): string {
    if (!bytes) return '';
    const gb = bytes / (1024 * 1024 * 1024);
    if (gb >= 1) return `${gb.toFixed(1)} GB`;
    const mb = bytes / (1024 * 1024);
    return `${mb.toFixed(0)} MB`;
}
